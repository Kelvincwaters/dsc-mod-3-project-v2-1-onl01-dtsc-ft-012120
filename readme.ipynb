{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The project:\n",
    "A credit card fraud detection kaggle dataset [here](https://www.kaggle.com/mlg-ulb/creditcardfraud). The dataset is without a dictionary and the majority of the features were obscured (maybe a result of a PCA dimensionality reduction to protect users identities and sensitive features). It expands 31 columns and over 280,000 rows @ 144MB and the majority of the features are continuous. There aren't any outliers and the data appears to be normalized. There's a major issue with this dataset, the extremely imbalanced target/dependent variable 'Class'. The columns and descriptions in the dataset are as follows:\n",
    "\n",
    "```python\n",
    "       df.columns\n",
    "Index(['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10',\n",
    "       'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20',\n",
    "       'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount',\n",
    "       'Class'],\n",
    "      dtype='object')\n",
    "```\n",
    "\n",
    "#### The models being considered: \n",
    "1. Logistic Regression\n",
    "1. Decision Tree\n",
    "1. Random Forest \n",
    "1. XGBoost\n",
    "\n",
    "#### The metrics being considered:\n",
    "1. Precison\n",
    "1. Recall\n",
    "1. Accuracy\n",
    "1. F1-score\n",
    "\n",
    "  > Note: The choice of which metric to pursue depends on the business objective and that objective being the precision metric, being able to ensure that the bank isn't \"left holding the bag\" on fraudulent transactions. Thus the focus of this notebook was on the precision metric.\n",
    "\n",
    "#### Use of SMOTE\n",
    "Oversampling the minority dependent variable was the chosen path and subsequently led to an almost a quater of a million additional data points. The initial imbalance for a 227451 to 394 split! \n",
    "\n",
    "```python\n",
    "# instantiate a smote obj\n",
    "smote = SMOTE(random_state= 42) \n",
    "\n",
    "# apply smote to training data NOT the testing data\n",
    "X_train_smote, y_train_smote = smote.fit_sample(X_train, y_train)\n",
    "\n",
    "# verifying the 'smoting' results!\n",
    "# more data points is preferable than fewer data points when it comes to machine learning\n",
    "print('Before SMOTE :', Counter(y_train))\n",
    "print('After SMOTE :', Counter(y_train_smote))\n",
    "\n",
    "Before SMOTE : Counter({0: 227451, 1: 394})\n",
    "After SMOTE : Counter({0: 227451, 1: 227451})\n",
    "\n",
    "```\n",
    "```python\n",
    "X_train_smote.shape\n",
    "(454902, 30)\n",
    "\n",
    "y_train_smote.shape\n",
    "(454902,)\n",
    "\n",
    "```\n",
    "#### Use of pipelines (Houston we have a problem)\n",
    "I attempted to utilized pipelines just for passing in GridSearchCV parameters since there was no use in creating dummies through sklearn via ColumnTransformer and a scaler seeing as how this dataset was already normalized. Using pipelines on the initial imbalanced data worked as expected but couldn't complete at all when presented with the smoted X_train_smoted, y_train_smoted parameters. An exhaustive google search returned an issue with SMOTE perhaps running on a single core (in a multicore system) but to no avail no workaround was discovered. \n",
    "\n",
    "```python\n",
    "# logistic Regression\n",
    "pipe_lr = Pipeline([('pca', PCA(n_components= 2)),\n",
    "            ('clf', LogisticRegression(random_state= 42))])\n",
    "# SVM\n",
    "pipe_svm = Pipeline([('pca', PCA(n_components= 2)),\n",
    "            ('clf', svm.SVC(random_state= 42))])\n",
    "# Decision Tree            \n",
    "pipe_dt = Pipeline([('pca', PCA(n_components= 2)),\n",
    "            ('clf', tree.DecisionTreeClassifier(random_state= 42))])\n",
    "\n",
    "\n",
    "# List of pipelines for ease of iteration\n",
    "pipelines = [pipe_lr, pipe_svm, pipe_dt]\n",
    "\n",
    "# Dictionary of pipelines and classifier types for ease of reference\n",
    "pipe_dict = {0: 'Logistic Regression', 1: 'Support Vector Machine', 2: 'Decision Tree'}\n",
    "\n",
    "# Fit the pipelines\n",
    "for pipe in pipelines:\n",
    "    pipe.fit(X_train_smote, y_train_smote) # will NOT complete with balanced smoted training data!\n",
    "```\n",
    "\n",
    "#### Use of GridSearchCV:\n",
    "Each model was initially ran with default parameters which were recorded then subjected to a GridSearchCV which included the default parameters as well as additional ones, all with 5 K-Fold validation. \n",
    "\n",
    "```python\n",
    "# default values are first in each dict list\n",
    "param_grid = {\n",
    "    'n_estimators': [10, 100],\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'n_jobs': [None, -1]\n",
    "}\n",
    "gs_forest = GridSearchCV(forest, param_grid, cv=5) # 5 K fold\n",
    "gs_forest.fit(X_train_smote, y_train_smote)\n",
    "gs_forest.best_params_\n",
    "\n",
    "{'criterion': 'entropy', 'n_estimators': 100, 'n_jobs': None} results! \n",
    "```\n",
    "\n",
    "#### The Results:\n",
    "1. First place Random Forest classifier @ 99% in both Precision and accucracy\n",
    "1. Second place XGBoost @ 96% in Precision and 99% in accuracy\n",
    "1. Third was Logitistic Regression (balanced) @ 93% accuracy and 99 accuracy\n",
    "1. Last is a Decision Tree @ 89% precision and an accuracy of over 99% (as the others)\n",
    "\n",
    "<img src= model_results.jpg width=300>\n",
    "\n",
    "\n",
    "```python\n",
    "# Instantiate and fit a RandomForestClassifier\n",
    "forest = RandomForestClassifier(criterion= 'entropy', n_estimators= 100, n_jobs= None)\n",
    "\n",
    "# fit\n",
    "forest.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# predict\n",
    "forest_predict = forest.predict(X_test) # this can't be right, smote isn't applied to testing values\n",
    "\n",
    "# train accuracy score\n",
    "forest.score(X_train_smote, y_train_smote)\n",
    "\n",
    "# test accuracy score\n",
    "forest.score(X_test, y_test)      \n",
    "\n",
    "# default 1.0\n",
    "\n",
    "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
    "                       criterion='entropy', max_depth=None, max_features='auto',\n",
    "                       max_leaf_nodes=None, max_samples=None,\n",
    "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                       min_samples_leaf=1, min_samples_split=2,\n",
    "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
    "                       n_jobs=None, oob_score=False, random_state=None,\n",
    "                       verbose=0, warm_start=False)\n",
    "\n",
    "Confusion Matrix:\n",
    " [[56863     1]\n",
    " [   21    77]]\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       1.00      1.00      1.00     56864\n",
    "           1       0.99      0.79      0.88        98\n",
    "\n",
    "    accuracy                           1.00     56962\n",
    "   macro avg       0.99      0.89      0.94     56962\n",
    "weighted avg       1.00      1.00      1.00     56962\n",
    "```\n",
    "\n",
    "#### Future work:\n",
    "Would be nice to know what the hidden features are and test for multicollinearity and maybe ascertain if there's any correlation of fraudulent transaction detection during a specific time of day, month ... this could clearly be indentified by the metrics captured with each and every credit card transaction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
